{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In notebook **3_build_model**, we let all the weights of the resnet model be updated when fine tuning on the EuroSAT dataset. One other way to finetune would be to only modify the weights of the final fully connected layer and freeze the other weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: \n",
    "1. Load resnet50 model\n",
    "2. Load train,val,test data\n",
    "3. Freeze all except the final fully connected layer \n",
    "4. Train the model \n",
    "5. Get performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import tqdm\n",
    "from torchvision import models\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights = models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #If running from colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# data_folder = '/content/drive/MyDrive/CCAI 2024 Tutorials/1_LULC_ResNET50/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If running locally\n",
    "data_folder = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(os.path.join(data_folder, 'EuroSAT','2750'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AnnualCrop',\n",
       " 'Forest',\n",
       " 'HerbaceousVegetation',\n",
       " 'Highway',\n",
       " 'Industrial',\n",
       " 'Pasture',\n",
       " 'PermanentCrop',\n",
       " 'Residential',\n",
       " 'River',\n",
       " 'SeaLake']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FD826ECBA60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FD826EC41F0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10000][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSAT(data.Dataset):\n",
    "    def __init__(self,dataset,transform = None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        if self.transform:\n",
    "            x = self.transform(dataset[index][0])\n",
    "        else:\n",
    "            x = dataset[index][0]\n",
    "        y = dataset[index][1]\n",
    "        return x,y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-0b32d987e57a>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_loader = torch.load(os.path.join(data_folder,'train_loader.pth'))\n",
      "<ipython-input-10-0b32d987e57a>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_loader = torch.load(os.path.join(data_folder,'val_loader.pth'))\n",
      "<ipython-input-10-0b32d987e57a>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_loader = torch.load(os.path.join(data_folder,'test_loader.pth'))\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.load(os.path.join(data_folder,'train_loader.pth'))\n",
    "val_loader = torch.load(os.path.join(data_folder,'val_loader.pth'))\n",
    "test_loader = torch.load(os.path.join(data_folder,'test_loader.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(model.fc.in_features,len(dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check is GPU is enabled\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "# Get specific GPU model\n",
    "if str(device) == \"cuda:0\":\n",
    "  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model,input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(model.fc.in_features,len(dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr = lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_total_correct = 0.0\n",
    "\n",
    "    for i,(inputs,labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # print(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        _,preds = torch.max(outputs,1)\n",
    "\n",
    "        running_loss += loss.item() *inputs.size(0)\n",
    "        running_total_correct += torch.sum(preds == labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_accuracy = (running_total_correct /  len(dataloader.dataset)) * 100\n",
    "    print(f'Train loss : {epoch_loss:.2f};Accuracy : {epoch_accuracy:.2f}')\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataloader,criterion,phase='val'):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_total_correct = 0.0\n",
    "\n",
    "    for i,(inputs,labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            _, preds = torch.max(outputs,1)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_total_correct += torch.sum(preds == labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_accuracy = (running_total_correct / len(dataloader.dataset)) * 100\n",
    "    print(f'{phase.title()} Loss = {epoch_loss:.2f}; Accuracy = {epoch_accuracy:.2f}')\n",
    "\n",
    "    return epoch_loss,epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model,train_loader,val_loader,n_epochs,lr,criterion,optimizer):\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch : {epoch+1}')\n",
    "        train(model,train_loader,criterion,optimizer)\n",
    "        val_loss,_ = evaluate(model,val_loader,criterion)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fit(model,train_loader,val_loader,n_epochs = epochs,criterion=criterion)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
